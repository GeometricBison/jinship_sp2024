{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: ctransformers[cuda]\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /private/var/folders/bl/kzfk5ts90gj98y9jcv49ynmc0000gn/T/pip-req-build-5ybx7zup\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /private/var/folders/bl/kzfk5ts90gj98y9jcv49ynmc0000gn/T/pip-req-build-5ybx7zup\n",
      "  Resolved https://github.com/huggingface/transformers to commit d45f47ab7f7c31991bb98a0302ded59ab6adac31\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.9/site-packages (from transformers==4.39.0.dev0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->transformers==4.39.0.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->transformers==4.39.0.dev0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->transformers==4.39.0.dev0) (2024.2.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.39.0.dev0-py3-none-any.whl size=8662893 sha256=6fe08beccbac81965e2994652e460873a2ea8b561506f33232dda833a4015ba8\n",
      "  Stored in directory: /private/var/folders/bl/kzfk5ts90gj98y9jcv49ynmc0000gn/T/pip-ephem-wheel-cache-k1vrzt_d/wheels/14/a0/7b/8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.38.2\n",
      "    Uninstalling transformers-4.38.2:\n",
      "      Successfully uninstalled transformers-4.38.2\n",
      "Successfully installed transformers-4.39.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install ctransformers[cuda]\n",
    "!pip install --upgrade git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushjain/Development/DisruptionLab/jinship_sp2024/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/ayushjain/Development/DisruptionLab/jinship_sp2024/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 12710.01it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 22795.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/zephyr-7B-alpha-GGUF\",\n",
    "    model_file=\"zephyr-7b-alpha.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    gpu_layers=0,\n",
    "    hf=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")\n",
    "\n",
    "# Pipeline\n",
    "generator = pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    max_new_tokens=50,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<|system|>You are a helpful, respectful and honest assistant for labeling topics..</s>\n",
    "<|user|>\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.</s>\n",
    "<|assistant|>\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import TextGeneration\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Text generation with Zephyr\n",
    "zephyr = TextGeneration(generator, prompt=prompt)\n",
    "representation_model = {\"Zephyr\": zephyr}\n",
    "\n",
    "# Topic Modeling\n",
    "topic_model = BERTopic(representation_model=representation_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"valurank/Topic_Classification\")[\"train\"]\n",
    "\n",
    "# Extract abstracts to train on and corresponding titles\n",
    "descriptions = dataset[\"article_text\"]\n",
    "topics = dataset[\"topic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 23:41:54,296 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Error during conversion: ValueError('Queue is full! Please try again.')\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "2024-03-06 23:41:55,951 - BERTopic - Embedding - Completed ✓\n",
      "2024-03-06 23:41:55,951 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "Exception in thread Thread-autoconversion:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/ayushjain/Development/DisruptionLab/jinship_sp2024/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayushjain/Development/DisruptionLab/jinship_sp2024/.venv/lib/python3.9/site-packages/transformers/safetensors_conversion.py\", line 89, in auto_conversion\n",
      "    sha = get_conversion_pr_reference(api, pretrained_model_name_or_path, **cached_file_kwargs)\n",
      "  File \"/Users/ayushjain/Development/DisruptionLab/jinship_sp2024/.venv/lib/python3.9/site-packages/transformers/safetensors_conversion.py\", line 82, in get_conversion_pr_reference\n",
      "    sha = f\"refs/pr/{pr.num}\"\n",
      "AttributeError: 'NoneType' object has no attribute 'num'\n",
      "2024-03-06 23:41:59,484 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-03-06 23:41:59,485 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-03-06 23:41:59,491 - BERTopic - Cluster - Completed ✓\n",
      "2024-03-06 23:41:59,495 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Number of tokens (7507) exceeded maximum context length (512).\n",
      "Number of tokens (7508) exceeded maximum context length (512).\n",
      "Number of tokens (7509) exceeded maximum context length (512).\n",
      "Number of tokens (7510) exceeded maximum context length (512).\n",
      "Number of tokens (7511) exceeded maximum context length (512).\n",
      "Number of tokens (7512) exceeded maximum context length (512).\n",
      "Number of tokens (7513) exceeded maximum context length (512).\n",
      "Number of tokens (7514) exceeded maximum context length (512).\n",
      "Number of tokens (7515) exceeded maximum context length (512).\n",
      "Number of tokens (7516) exceeded maximum context length (512).\n",
      "Number of tokens (7517) exceeded maximum context length (512).\n",
      "Number of tokens (7518) exceeded maximum context length (512).\n",
      "Number of tokens (7519) exceeded maximum context length (512).\n",
      "Number of tokens (7520) exceeded maximum context length (512).\n",
      "Number of tokens (7521) exceeded maximum context length (512).\n",
      "Number of tokens (7522) exceeded maximum context length (512).\n",
      "Number of tokens (7523) exceeded maximum context length (512).\n",
      "Number of tokens (7524) exceeded maximum context length (512).\n",
      "Number of tokens (7525) exceeded maximum context length (512).\n",
      "Number of tokens (7526) exceeded maximum context length (512).\n",
      "Number of tokens (7527) exceeded maximum context length (512).\n",
      "Number of tokens (7528) exceeded maximum context length (512).\n",
      "Number of tokens (7529) exceeded maximum context length (512).\n",
      "Number of tokens (7530) exceeded maximum context length (512).\n",
      "Number of tokens (7531) exceeded maximum context length (512).\n",
      "Number of tokens (7532) exceeded maximum context length (512).\n",
      "Number of tokens (7533) exceeded maximum context length (512).\n",
      "Number of tokens (7534) exceeded maximum context length (512).\n",
      "Number of tokens (7535) exceeded maximum context length (512).\n",
      "Number of tokens (7536) exceeded maximum context length (512).\n",
      "Number of tokens (7537) exceeded maximum context length (512).\n",
      "Number of tokens (7538) exceeded maximum context length (512).\n",
      "Number of tokens (7539) exceeded maximum context length (512).\n",
      "Number of tokens (7540) exceeded maximum context length (512).\n",
      "Number of tokens (7541) exceeded maximum context length (512).\n",
      "Number of tokens (7542) exceeded maximum context length (512).\n",
      "Number of tokens (7543) exceeded maximum context length (512).\n",
      "Number of tokens (7544) exceeded maximum context length (512).\n",
      "Number of tokens (7545) exceeded maximum context length (512).\n",
      "Number of tokens (7546) exceeded maximum context length (512).\n",
      "Number of tokens (7547) exceeded maximum context length (512).\n",
      "Number of tokens (7548) exceeded maximum context length (512).\n",
      "Number of tokens (7549) exceeded maximum context length (512).\n",
      "Number of tokens (7550) exceeded maximum context length (512).\n",
      "Number of tokens (7551) exceeded maximum context length (512).\n",
      "Number of tokens (7552) exceeded maximum context length (512).\n",
      "Number of tokens (7553) exceeded maximum context length (512).\n",
      "Number of tokens (7554) exceeded maximum context length (512).\n",
      "Number of tokens (7555) exceeded maximum context length (512).\n",
      "Number of tokens (7556) exceeded maximum context length (512).\n",
      "100%|██████████| 1/1 [07:53<00:00, 473.77s/it]\n",
      "2024-03-06 23:49:53,297 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bertopic._bertopic.BERTopic at 0x1038a3160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.fit(descriptions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
